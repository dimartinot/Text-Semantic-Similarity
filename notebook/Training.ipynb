{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training-Notebook\" data-toc-modified-id=\"Training-Notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training Notebook</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-Constants\" data-toc-modified-id=\"Imports-&amp;-Constants-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports &amp; Constants</a></span></li><li><span><a href=\"#Loading-data-&amp;-processing-pipeline\" data-toc-modified-id=\"Loading-data-&amp;-processing-pipeline-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Loading data &amp; processing pipeline</a></span></li><li><span><a href=\"#Part-I:-Training-the-distance-model\" data-toc-modified-id=\"Part-I:-Training-the-distance-model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Part I: Training the distance model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Instantiating-model,-loss-and-optimizer\" data-toc-modified-id=\"Instantiating-model,-loss-and-optimizer-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Instantiating model, loss and optimizer</a></span></li><li><span><a href=\"#Training-&amp;-Validation-loops\" data-toc-modified-id=\"Training-&amp;-Validation-loops-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Training &amp; Validation loops</a></span></li></ul></li><li><span><a href=\"#Part-II:-Training-the-distance-classifier\" data-toc-modified-id=\"Part-II:-Training-the-distance-classifier-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Part II: Training the distance classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataloaders-creation\" data-toc-modified-id=\"Dataloaders-creation-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Dataloaders creation</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook\n",
    "---\n",
    "In this notebook, we will train our model to perform data similarity detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Used to import libraries from an absolute path starting with the project's root\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Local imports\n",
    "from src.dataset.similarityVectorizedDataset import SimilarityVectorizedDataset\n",
    "from src.model.contrastiveModel import ContrastiveLoss, SiameseContrastiveLoss, TextSimilarityLSTM, TextSimilarityDeepSiameseLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda:0\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EMBEDDING_DIM = 40\n",
    "EPOCHS = 25\n",
    "TRAIN = 0.8\n",
    "TEST = 0.1\n",
    "VAL = 0.1\n",
    "SHUFFLE = True\n",
    "SEED = 42\n",
    "LR = 1e-3\n",
    "TO_SAVE = True\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device used: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data & processing pipeline\n",
    "We are loading the PyTorch compatible Dataset class and create 3 dataloaders, one per set of data (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_collate(batch):\n",
    "    \"\"\"\n",
    "        Used as a PyTorch collate_fn function in PyTorch dataloaders. \n",
    "        Given a batch of vectors of shape (word_count, word_size), \n",
    "        make the word_count of each sequence uniform by doing right-side 0 padding.\n",
    "        \n",
    "        /!\\ The sequences size between batches may vary /!\\\n",
    "    \"\"\"\n",
    "    \n",
    "    max_shape_val = max(\n",
    "        [\n",
    "                #b[0] to get X, b[0][0] to get the first sentence of every X, b[0][1] to get the second sentence of every X\n",
    "            max(b[0][0].shape[0], b[0][1].shape[0]) for b in batch\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    y = [] \n",
    "        \n",
    "    for i in range(len(batch)):\n",
    "        \n",
    "        #batch[i][0] is X, batch[i][1] is y\n",
    "        x1 = batch[i][0][0]\n",
    "                    \n",
    "        if x1.shape[0] < max_shape_val:            \n",
    "            to_be_padded_shape = (max_shape_val - x1.shape[0], x1.shape[1])\n",
    "            padding = torch.zeros(to_be_padded_shape)\n",
    "            x1 = torch.cat((x1, padding), dim=0)\n",
    "                \n",
    "        x2 = batch[i][0][1]\n",
    "        \n",
    "        if x2.shape[0] < max_shape_val:            \n",
    "            to_be_padded_shape = (max_shape_val - x2.shape[0], x2.shape[1])\n",
    "            padding = torch.zeros(to_be_padded_shape)\n",
    "            x2 = torch.cat((x2, padding), dim=0)\n",
    "    \n",
    "        X1.append(x1)\n",
    "        X2.append(x2)\n",
    "                \n",
    "        y.append([batch[i][1]])\n",
    "    \n",
    "    X1 = torch.stack(X1)\n",
    "    X2 = torch.stack(X2)\n",
    "    \n",
    "    return (X1, X2), torch.FloatTensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloaders..\n"
     ]
    }
   ],
   "source": [
    "dataset = SimilarityVectorizedDataset()\n",
    "\n",
    "# Data preparation \n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "val_split = int(np.floor(VAL * dataset_size))\n",
    "test_split = int(np.floor(TEST * dataset_size))\n",
    "\n",
    "if SHUFFLE:\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices, test_indices = indices[val_split+test_split:], indices[:val_split], indices[val_split:val_split+test_split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "num_train_batch = int(np.ceil(TRAIN * dataset_size / BATCH_SIZE))\n",
    "num_val_batch = int(np.ceil(VAL * dataset_size / BATCH_SIZE))\n",
    "num_test_batch = int(np.ceil(TEST * dataset_size / BATCH_SIZE))\n",
    "\n",
    "print(\"Creating dataloaders..\")\n",
    "\n",
    "dataloader_train = torch.utils.data.dataloader.DataLoader(\n",
    "    dataset = dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = padding_collate,\n",
    "    sampler = train_sampler\n",
    ")\n",
    "\n",
    "dataloader_val = torch.utils.data.dataloader.DataLoader(\n",
    "    dataset = dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = padding_collate,\n",
    "    sampler = val_sampler\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.dataloader.DataLoader(\n",
    "    dataset = dataset,\n",
    "    collate_fn = padding_collate,\n",
    "    sampler = test_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Training the distance model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating model, loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.model.contrastiveModel' from 'D:\\\\thoma\\\\GitHub\\\\Text-Semantic-Similarity\\\\src\\\\model\\\\contrastiveModel.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.model.contrastiveModel\n",
    "importlib.reload(src.model.contrastiveModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = src.model.contrastiveModel.TextSimilarityDeepSiameseLSTM(embedding_dim = EMBEDDING_DIM)\n",
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "contrastive_loss = src.model.contrastiveModel.SiameseContrastiveLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 0\n",
      " Epochs 0 - Loss: 0.4739177591795029 - Acc: 0 - Batch: 2527/2527 - Dur: 307.12s/307.12ss\n",
      "\n",
      " Epochs 0 - Val_loss: 0.4337922085689593 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 1\n",
      " Epochs 1 - Loss: 0.41653011171394155 - Acc: 0 - Batch: 2527/2527 - Dur: 324.34s/324.34s\n",
      "\n",
      " Epochs 1 - Val_loss: 0.40398977725188945 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 2\n",
      " Epochs 2 - Loss: 0.3992016296000834 - Acc: 0 - Batch: 2527/2527 - Dur: 341.14s/341.14ss\n",
      "\n",
      " Epochs 2 - Val_loss: 0.39798272165316567 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 3\n",
      " Epochs 3 - Loss: 0.38566131262992465 - Acc: 0 - Batch: 2527/2527 - Dur: 324.73s/324.73s\n",
      "\n",
      " Epochs 3 - Val_loss: 0.38479179672048064 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 4\n",
      " Epochs 4 - Loss: 0.3748073286933771 - Acc: 0 - Batch: 2527/2527 - Dur: 329.56s/329.56ss\n",
      "\n",
      " Epochs 4 - Val_loss: 0.37326180067243453 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 5\n",
      " Epochs 5 - Loss: 0.36375394935281463 - Acc: 0 - Batch: 2527/2527 - Dur: 337.96s/337.96s\n",
      "\n",
      " Epochs 5 - Val_loss: 0.36442020568477956 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 6\n",
      " Epochs 6 - Loss: 0.3538943480067825 - Acc: 0 - Batch: 2527/2527 - Dur: 364.7s/364.7s77s\n",
      "\n",
      " Epochs 6 - Val_loss: 0.3584587843735007 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 7\n",
      " Epochs 7 - Loss: 0.3456910247087101 - Acc: 0 - Batch: 2527/2527 - Dur: 305.3s/305.3ssss\n",
      "\n",
      " Epochs 7 - Val_loss: 0.3516994373330587 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 8\n",
      " Epochs 8 - Loss: 0.33762302384411436 - Acc: 0 - Batch: 2527/2527 - Dur: 308.43s/308.43s\n",
      "\n",
      " Epochs 8 - Val_loss: 0.3506086949683443 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 9\n",
      " Epochs 9 - Loss: 0.33121349473550565 - Acc: 0 - Batch: 2527/2527 - Dur: 335.27s/335.27s\n",
      "\n",
      " Epochs 9 - Val_loss: 0.34136485827120044 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 10\n",
      " Epochs 10 - Loss: 0.3247741954655434 - Acc: 0 - Batch: 2527/2527 - Dur: 315.17s/315.17ss\n",
      "\n",
      " Epochs 10 - Val_loss: 0.33738706378808503 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 11\n",
      " Epochs 11 - Loss: 0.31918774664897337 - Acc: 0 - Batch: 2527/2527 - Dur: 320.09s/320.09s\n",
      "\n",
      " Epochs 11 - Val_loss: 0.34212289194140255 - Batch: 316/316\n",
      "---\n",
      "Epochs 12\n",
      " Epochs 12 - Loss: 0.3138341423924563 - Acc: 0 - Batch: 2527/2527 - Dur: 336.31s/336.31ss\n",
      "\n",
      " Epochs 12 - Val_loss: 0.33299933100425744 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 13\n",
      " Epochs 13 - Loss: 0.30881141398587053 - Acc: 0 - Batch: 2527/2527 - Dur: 324.26s/324.26s\n",
      "\n",
      " Epochs 13 - Val_loss: 0.3288513726637333 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 14\n",
      " Epochs 14 - Loss: 0.30440917745568696 - Acc: 0 - Batch: 2527/2527 - Dur: 334.84s/334.84s\n",
      "\n",
      " Epochs 14 - Val_loss: 0.32633621637013893 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 15\n",
      " Epochs 15 - Loss: 0.29967837808134057 - Acc: 0 - Batch: 2527/2527 - Dur: 322.35s/322.35s\n",
      "\n",
      " Epochs 15 - Val_loss: 0.3239117674057997 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 16\n",
      " Epochs 16 - Loss: 0.2958357107818575 - Acc: 0 - Batch: 2527/2527 - Dur: 315.64s/315.64ss\n",
      "\n",
      " Epochs 16 - Val_loss: 0.32364298360823074 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 17\n",
      " Epochs 17 - Loss: 0.29143609864866493 - Acc: 0 - Batch: 2527/2527 - Dur: 333.51s/333.51s\n",
      "\n",
      " Epochs 17 - Val_loss: 0.32312307888759845 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 18\n",
      " Epochs 18 - Loss: 0.28807538425823326 - Acc: 0 - Batch: 2527/2527 - Dur: 324.12s/324.12s\n",
      "\n",
      " Epochs 18 - Val_loss: 0.31884574333700955 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 19\n",
      " Epochs 19 - Loss: 0.284060590656133 - Acc: 0 - Batch: 2527/2527 - Dur: 335.94s/335.94sss\n",
      "\n",
      " Epochs 19 - Val_loss: 0.3181567868760115 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 20\n",
      " Epochs 20 - Loss: 0.2803972782261248 - Acc: 0 - Batch: 2527/2527 - Dur: 329.41s/329.41ss\n",
      "\n",
      " Epochs 20 - Val_loss: 0.3189483435848091 - Batch: 316/3166\n",
      "---\n",
      "Epochs 21\n",
      " Epochs 21 - Loss: 0.27709212880338374 - Acc: 0 - Batch: 2527/2527 - Dur: 329.41s/329.41s\n",
      "\n",
      " Epochs 21 - Val_loss: 0.3185362667316877 - Batch: 316/3166\n",
      "---\n",
      "Epochs 22\n",
      " Epochs 22 - Loss: 0.2734834705127479 - Acc: 0 - Batch: 2527/2527 - Dur: 335.58s/335.58ss\n",
      "\n",
      " Epochs 22 - Val_loss: 0.31838054846547825 - Batch: 316/316\n",
      "---\n",
      "Epochs 23\n",
      " Epochs 23 - Loss: 0.2709767412634579 - Acc: 0 - Batch: 2527/2527 - Dur: 322.42s/322.42ss\n",
      "\n",
      " Epochs 23 - Val_loss: 0.31436204070909113 - Batch: 316/316Saving weights..\n",
      "\n",
      "---\n",
      "Epochs 24\n",
      " Epochs 24 - Loss: 0.26813035636114235 - Acc: 0 - Batch: 2527/2527 - Dur: 334.24s/334.24s\n",
      "\n",
      " Epochs 24 - Val_loss: 0.3168674270280554 - Batch: 316/3166\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "min_val_loss = np.inf\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "    print(f\"Epochs {i}\")\n",
    "    n = 1\n",
    "    total_loss = 0\n",
    "    total_duration = 0\n",
    "    t0 = time.time()\n",
    "    total_timesteps = len(dataloader_train)\n",
    "\n",
    "\n",
    "    for local_batch, local_labels in dataloader_train:\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Transfer to GPU\n",
    "        local_batch_X1, local_batch_X2, local_labels = local_batch[0].to(device), local_batch[1].to(device), local_labels.to(device)\n",
    "\n",
    "        preds = model(local_batch_X1, local_batch_X2)\n",
    "\n",
    "        # Compute the loss, gradients, and update the parameters by\n",
    "        #loss = loss_function(preds, local_labels)\n",
    "        loss = contrastive_loss(preds, local_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics to follow progress\n",
    "        total_loss += loss.item()\n",
    "        duration = time.time() - t0\n",
    "        total_duration += duration\n",
    "        total_duration = round(total_duration, 2)\n",
    "\n",
    "        estimated_duration_left = round((total_duration / n) * (total_timesteps), 2)\n",
    "\n",
    "        print(f\"\\r Epochs {i} - Loss: {total_loss/n} - Acc: {0} - Batch: {n}/{num_train_batch} - Dur: {total_duration}s/{estimated_duration_left}s\", end=\"\")\n",
    "        n+=1\n",
    "        t0 = time.time()\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # End of epochs validation\n",
    "\n",
    "    n = 1\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for local_batch, local_labels in dataloader_val:\n",
    "            # Transfer to GPU\n",
    "            local_batch_X1, local_batch_X2, local_labels = local_batch[0].to(device), local_batch[1].to(device), local_labels.to(device)\n",
    "\n",
    "            preds = model(local_batch_X1, local_batch_X2)\n",
    "\n",
    "            loss = contrastive_loss(preds, local_labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            acc=0\n",
    "            print(f\"\\r Epochs {i} - Val_loss: {total_loss/n} - Batch: {n}/{num_val_batch}\", end=\"\")\n",
    "            n+=1\n",
    "\n",
    "        if TO_SAVE and total_loss < min_val_loss:\n",
    "            print(\"Saving weights..\")\n",
    "            date = datetime.now().strftime(\"%m_%d_%H_%M_%S\" )\n",
    "            torch.save(model.state_dict(), f\"siamese_lstm_sequence_{date}_epoch{i}.pt\")\n",
    "            \n",
    "            min_val_loss = total_loss\n",
    "\n",
    "        model.train()\n",
    "    print(\"\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%m_%d_%H_%M_%S\" )\n",
    "torch.save(model.state_dict(), f\"siamese_smaller_lstm_sequence_{date}_epoch{i}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Training the distance classifier\n",
    "### Dataloaders creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_and_titles_to_distance_dataset(model, dataloader):\n",
    "    \"\"\"\n",
    "    Given a similarity learning model and a dataloader, transforms the data of the dataloader in the shape of a distance dataset.\n",
    "    The distances are computed using the model. We then use the target variables to train a linear model to classify the distances\n",
    "    to 2 different classes: similar or dissimilar.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    n = 1\n",
    "    \n",
    "    total_duration = 0\n",
    "    total_steps = len(dataloader)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for local_batch, local_labels in dataloader:\n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Transfer to GPU\n",
    "        local_batch_X1, local_batch_X2, local_labels = local_batch[0].to(device), local_batch[1].to(device), local_labels.to(device)\n",
    "\n",
    "        preds = model(local_batch_X1, local_batch_X2)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Transfering distances and labels to cpu\n",
    "            distances_cpu = preds.cpu().numpy().reshape(-1, 1)\n",
    "            labels = torch.flatten(local_labels).cpu().numpy().reshape(-1, 1)\n",
    "            # Fitting logreg\n",
    "            X.append(distances_cpu)\n",
    "            y.append(labels)\n",
    "        \n",
    "        duration = time.time() - t0\n",
    "        \n",
    "        total_duration += duration\n",
    "        \n",
    "        per_step_mean_duration = total_duration / n\n",
    "        rest_of_time = per_step_mean_duration * (total_steps)\n",
    "        \n",
    "        n+=1\n",
    "        print(f\"\\r{n}-{total_steps} (ETA: {total_duration}/{rest_of_time}s)\", end=\"\")\n",
    "        \n",
    "    model.train()\n",
    "        \n",
    "    X = np.array(X).flatten().reshape(-1, 1)\n",
    "    y = np.array(y).flatten()\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.dataloader.DataLoader(\n",
    "    dataset = dataset,\n",
    "    collate_fn = padding_collate,\n",
    "    sampler = train_sampler\n",
    ")\n",
    "\n",
    "dataloader_val = torch.utils.data.dataloader.DataLoader(\n",
    "    dataset = dataset,\n",
    "    collate_fn = padding_collate,\n",
    "    sampler = val_sampler\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.dataloader.DataLoader(\n",
    "    dataset = dataset,\n",
    "    collate_fn = padding_collate,\n",
    "    sampler = test_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training dataset...\n",
      "323405-323404 (ETA: 2826.7109677791595/2826.7109677791595s)Generating validation dataset...\n",
      "40426-40425 (ETA: 351.84866738319397/351.84866738319397s)Generating test dataset...\n",
      "40426-40425 (ETA: 351.76795291900635/351.76795291900635s)"
     ]
    }
   ],
   "source": [
    "print(\"Generating training dataset...\")\n",
    "X_train, y_train = model_and_titles_to_distance_dataset(model, dataloader_train)\n",
    "\n",
    "print(\"Generating validation dataset...\")\n",
    "X_test, y_test = model_and_titles_to_distance_dataset(model, dataloader_test)\n",
    "\n",
    "print(\"Generating test dataset...\")\n",
    "X_val, y_val = model_and_titles_to_distance_dataset(model, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final perfs: 0.7993654994990785 - 0.7652195423623995 - 0.7669758812615955\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "train_acc = logreg.score(X_train, y_train)\n",
    "val_acc = logreg.score(X_val, y_val)\n",
    "test_acc = logreg.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nFinal perfs: {train_acc} - {val_acc} - {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x2c4941ea648>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "plot_roc_curve(logreg, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
